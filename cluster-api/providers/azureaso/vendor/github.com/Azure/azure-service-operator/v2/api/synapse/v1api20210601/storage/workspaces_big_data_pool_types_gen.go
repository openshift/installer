// Code generated by azure-service-operator-codegen. DO NOT EDIT.
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
package storage

import (
	"github.com/Azure/azure-service-operator/v2/pkg/genruntime"
	"github.com/Azure/azure-service-operator/v2/pkg/genruntime/conditions"
	"github.com/Azure/azure-service-operator/v2/pkg/genruntime/configmaps"
	"github.com/Azure/azure-service-operator/v2/pkg/genruntime/core"
	"github.com/Azure/azure-service-operator/v2/pkg/genruntime/secrets"
	"github.com/pkg/errors"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime/schema"
)

// +kubebuilder:rbac:groups=synapse.azure.com,resources=workspacesbigdatapools,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups=synapse.azure.com,resources={workspacesbigdatapools/status,workspacesbigdatapools/finalizers},verbs=get;update;patch

// +kubebuilder:object:root=true
// +kubebuilder:subresource:status
// +kubebuilder:storageversion
// +kubebuilder:printcolumn:name="Ready",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="Severity",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].severity"
// +kubebuilder:printcolumn:name="Reason",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].reason"
// +kubebuilder:printcolumn:name="Message",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].message"
// Storage version of v1api20210601.WorkspacesBigDataPool
// Generator information:
// - Generated from: /synapse/resource-manager/Microsoft.Synapse/stable/2021-06-01/bigDataPool.json
// - ARM URI: /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Synapse/workspaces/{workspaceName}/bigDataPools/{bigDataPoolName}
type WorkspacesBigDataPool struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`
	Spec              WorkspacesBigDataPool_Spec   `json:"spec,omitempty"`
	Status            WorkspacesBigDataPool_STATUS `json:"status,omitempty"`
}

var _ conditions.Conditioner = &WorkspacesBigDataPool{}

// GetConditions returns the conditions of the resource
func (pool *WorkspacesBigDataPool) GetConditions() conditions.Conditions {
	return pool.Status.Conditions
}

// SetConditions sets the conditions on the resource status
func (pool *WorkspacesBigDataPool) SetConditions(conditions conditions.Conditions) {
	pool.Status.Conditions = conditions
}

var _ configmaps.Exporter = &WorkspacesBigDataPool{}

// ConfigMapDestinationExpressions returns the Spec.OperatorSpec.ConfigMapExpressions property
func (pool *WorkspacesBigDataPool) ConfigMapDestinationExpressions() []*core.DestinationExpression {
	if pool.Spec.OperatorSpec == nil {
		return nil
	}
	return pool.Spec.OperatorSpec.ConfigMapExpressions
}

var _ secrets.Exporter = &WorkspacesBigDataPool{}

// SecretDestinationExpressions returns the Spec.OperatorSpec.SecretExpressions property
func (pool *WorkspacesBigDataPool) SecretDestinationExpressions() []*core.DestinationExpression {
	if pool.Spec.OperatorSpec == nil {
		return nil
	}
	return pool.Spec.OperatorSpec.SecretExpressions
}

var _ genruntime.KubernetesResource = &WorkspacesBigDataPool{}

// AzureName returns the Azure name of the resource
func (pool *WorkspacesBigDataPool) AzureName() string {
	return pool.Spec.AzureName
}

// GetAPIVersion returns the ARM API version of the resource. This is always "2021-06-01"
func (pool WorkspacesBigDataPool) GetAPIVersion() string {
	return "2021-06-01"
}

// GetResourceScope returns the scope of the resource
func (pool *WorkspacesBigDataPool) GetResourceScope() genruntime.ResourceScope {
	return genruntime.ResourceScopeResourceGroup
}

// GetSpec returns the specification of this resource
func (pool *WorkspacesBigDataPool) GetSpec() genruntime.ConvertibleSpec {
	return &pool.Spec
}

// GetStatus returns the status of this resource
func (pool *WorkspacesBigDataPool) GetStatus() genruntime.ConvertibleStatus {
	return &pool.Status
}

// GetSupportedOperations returns the operations supported by the resource
func (pool *WorkspacesBigDataPool) GetSupportedOperations() []genruntime.ResourceOperation {
	return []genruntime.ResourceOperation{
		genruntime.ResourceOperationDelete,
		genruntime.ResourceOperationGet,
		genruntime.ResourceOperationPut,
	}
}

// GetType returns the ARM Type of the resource. This is always "Microsoft.Synapse/workspaces/bigDataPools"
func (pool *WorkspacesBigDataPool) GetType() string {
	return "Microsoft.Synapse/workspaces/bigDataPools"
}

// NewEmptyStatus returns a new empty (blank) status
func (pool *WorkspacesBigDataPool) NewEmptyStatus() genruntime.ConvertibleStatus {
	return &WorkspacesBigDataPool_STATUS{}
}

// Owner returns the ResourceReference of the owner
func (pool *WorkspacesBigDataPool) Owner() *genruntime.ResourceReference {
	group, kind := genruntime.LookupOwnerGroupKind(pool.Spec)
	return pool.Spec.Owner.AsResourceReference(group, kind)
}

// SetStatus sets the status of this resource
func (pool *WorkspacesBigDataPool) SetStatus(status genruntime.ConvertibleStatus) error {
	// If we have exactly the right type of status, assign it
	if st, ok := status.(*WorkspacesBigDataPool_STATUS); ok {
		pool.Status = *st
		return nil
	}

	// Convert status to required version
	var st WorkspacesBigDataPool_STATUS
	err := status.ConvertStatusTo(&st)
	if err != nil {
		return errors.Wrap(err, "failed to convert status")
	}

	pool.Status = st
	return nil
}

// Hub marks that this WorkspacesBigDataPool is the hub type for conversion
func (pool *WorkspacesBigDataPool) Hub() {}

// OriginalGVK returns a GroupValueKind for the original API version used to create the resource
func (pool *WorkspacesBigDataPool) OriginalGVK() *schema.GroupVersionKind {
	return &schema.GroupVersionKind{
		Group:   GroupVersion.Group,
		Version: pool.Spec.OriginalVersion,
		Kind:    "WorkspacesBigDataPool",
	}
}

// +kubebuilder:object:root=true
// Storage version of v1api20210601.WorkspacesBigDataPool
// Generator information:
// - Generated from: /synapse/resource-manager/Microsoft.Synapse/stable/2021-06-01/bigDataPool.json
// - ARM URI: /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Synapse/workspaces/{workspaceName}/bigDataPools/{bigDataPoolName}
type WorkspacesBigDataPoolList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []WorkspacesBigDataPool `json:"items"`
}

// Storage version of v1api20210601.WorkspacesBigDataPool_Spec
type WorkspacesBigDataPool_Spec struct {
	AutoPause *AutoPauseProperties `json:"autoPause,omitempty"`
	AutoScale *AutoScaleProperties `json:"autoScale,omitempty"`

	// AzureName: The name of the resource in Azure. This is often the same as the name of the resource in Kubernetes but it
	// doesn't have to be.
	AzureName                 string                             `json:"azureName,omitempty"`
	CacheSize                 *int                               `json:"cacheSize,omitempty"`
	CustomLibraries           []LibraryInfo                      `json:"customLibraries,omitempty"`
	DefaultSparkLogFolder     *string                            `json:"defaultSparkLogFolder,omitempty"`
	DynamicExecutorAllocation *DynamicExecutorAllocation         `json:"dynamicExecutorAllocation,omitempty"`
	IsAutotuneEnabled         *bool                              `json:"isAutotuneEnabled,omitempty"`
	IsComputeIsolationEnabled *bool                              `json:"isComputeIsolationEnabled,omitempty"`
	LibraryRequirements       *LibraryRequirements               `json:"libraryRequirements,omitempty"`
	Location                  *string                            `json:"location,omitempty"`
	NodeCount                 *int                               `json:"nodeCount,omitempty"`
	NodeSize                  *string                            `json:"nodeSize,omitempty"`
	NodeSizeFamily            *string                            `json:"nodeSizeFamily,omitempty"`
	OperatorSpec              *WorkspacesBigDataPoolOperatorSpec `json:"operatorSpec,omitempty"`
	OriginalVersion           string                             `json:"originalVersion,omitempty"`

	// +kubebuilder:validation:Required
	// Owner: The owner of the resource. The owner controls where the resource goes when it is deployed. The owner also
	// controls the resources lifecycle. When the owner is deleted the resource will also be deleted. Owner is expected to be a
	// reference to a synapse.azure.com/Workspace resource
	Owner                       *genruntime.KnownResourceReference `group:"synapse.azure.com" json:"owner,omitempty" kind:"Workspace"`
	PropertyBag                 genruntime.PropertyBag             `json:"$propertyBag,omitempty"`
	ProvisioningState           *string                            `json:"provisioningState,omitempty"`
	SessionLevelPackagesEnabled *bool                              `json:"sessionLevelPackagesEnabled,omitempty"`
	SparkConfigProperties       *SparkConfigProperties             `json:"sparkConfigProperties,omitempty"`
	SparkEventsFolder           *string                            `json:"sparkEventsFolder,omitempty"`
	SparkVersion                *string                            `json:"sparkVersion,omitempty"`
	Tags                        map[string]string                  `json:"tags,omitempty"`
}

var _ genruntime.ConvertibleSpec = &WorkspacesBigDataPool_Spec{}

// ConvertSpecFrom populates our WorkspacesBigDataPool_Spec from the provided source
func (pool *WorkspacesBigDataPool_Spec) ConvertSpecFrom(source genruntime.ConvertibleSpec) error {
	if source == pool {
		return errors.New("attempted conversion between unrelated implementations of github.com/Azure/azure-service-operator/v2/pkg/genruntime/ConvertibleSpec")
	}

	return source.ConvertSpecTo(pool)
}

// ConvertSpecTo populates the provided destination from our WorkspacesBigDataPool_Spec
func (pool *WorkspacesBigDataPool_Spec) ConvertSpecTo(destination genruntime.ConvertibleSpec) error {
	if destination == pool {
		return errors.New("attempted conversion between unrelated implementations of github.com/Azure/azure-service-operator/v2/pkg/genruntime/ConvertibleSpec")
	}

	return destination.ConvertSpecFrom(pool)
}

// Storage version of v1api20210601.WorkspacesBigDataPool_STATUS
type WorkspacesBigDataPool_STATUS struct {
	AutoPause                   *AutoPauseProperties_STATUS       `json:"autoPause,omitempty"`
	AutoScale                   *AutoScaleProperties_STATUS       `json:"autoScale,omitempty"`
	CacheSize                   *int                              `json:"cacheSize,omitempty"`
	Conditions                  []conditions.Condition            `json:"conditions,omitempty"`
	CreationDate                *string                           `json:"creationDate,omitempty"`
	CustomLibraries             []LibraryInfo_STATUS              `json:"customLibraries,omitempty"`
	DefaultSparkLogFolder       *string                           `json:"defaultSparkLogFolder,omitempty"`
	DynamicExecutorAllocation   *DynamicExecutorAllocation_STATUS `json:"dynamicExecutorAllocation,omitempty"`
	Id                          *string                           `json:"id,omitempty"`
	IsAutotuneEnabled           *bool                             `json:"isAutotuneEnabled,omitempty"`
	IsComputeIsolationEnabled   *bool                             `json:"isComputeIsolationEnabled,omitempty"`
	LastSucceededTimestamp      *string                           `json:"lastSucceededTimestamp,omitempty"`
	LibraryRequirements         *LibraryRequirements_STATUS       `json:"libraryRequirements,omitempty"`
	Location                    *string                           `json:"location,omitempty"`
	Name                        *string                           `json:"name,omitempty"`
	NodeCount                   *int                              `json:"nodeCount,omitempty"`
	NodeSize                    *string                           `json:"nodeSize,omitempty"`
	NodeSizeFamily              *string                           `json:"nodeSizeFamily,omitempty"`
	PropertyBag                 genruntime.PropertyBag            `json:"$propertyBag,omitempty"`
	ProvisioningState           *string                           `json:"provisioningState,omitempty"`
	SessionLevelPackagesEnabled *bool                             `json:"sessionLevelPackagesEnabled,omitempty"`
	SparkConfigProperties       *SparkConfigProperties_STATUS     `json:"sparkConfigProperties,omitempty"`
	SparkEventsFolder           *string                           `json:"sparkEventsFolder,omitempty"`
	SparkVersion                *string                           `json:"sparkVersion,omitempty"`
	Tags                        map[string]string                 `json:"tags,omitempty"`
	Type                        *string                           `json:"type,omitempty"`
}

var _ genruntime.ConvertibleStatus = &WorkspacesBigDataPool_STATUS{}

// ConvertStatusFrom populates our WorkspacesBigDataPool_STATUS from the provided source
func (pool *WorkspacesBigDataPool_STATUS) ConvertStatusFrom(source genruntime.ConvertibleStatus) error {
	if source == pool {
		return errors.New("attempted conversion between unrelated implementations of github.com/Azure/azure-service-operator/v2/pkg/genruntime/ConvertibleStatus")
	}

	return source.ConvertStatusTo(pool)
}

// ConvertStatusTo populates the provided destination from our WorkspacesBigDataPool_STATUS
func (pool *WorkspacesBigDataPool_STATUS) ConvertStatusTo(destination genruntime.ConvertibleStatus) error {
	if destination == pool {
		return errors.New("attempted conversion between unrelated implementations of github.com/Azure/azure-service-operator/v2/pkg/genruntime/ConvertibleStatus")
	}

	return destination.ConvertStatusFrom(pool)
}

// Storage version of v1api20210601.AutoPauseProperties
// Auto-pausing properties of a Big Data pool powered by Apache Spark
type AutoPauseProperties struct {
	DelayInMinutes *int                   `json:"delayInMinutes,omitempty"`
	Enabled        *bool                  `json:"enabled,omitempty"`
	PropertyBag    genruntime.PropertyBag `json:"$propertyBag,omitempty"`
}

// Storage version of v1api20210601.AutoPauseProperties_STATUS
// Auto-pausing properties of a Big Data pool powered by Apache Spark
type AutoPauseProperties_STATUS struct {
	DelayInMinutes *int                   `json:"delayInMinutes,omitempty"`
	Enabled        *bool                  `json:"enabled,omitempty"`
	PropertyBag    genruntime.PropertyBag `json:"$propertyBag,omitempty"`
}

// Storage version of v1api20210601.AutoScaleProperties
// Auto-scaling properties of a Big Data pool powered by Apache Spark
type AutoScaleProperties struct {
	Enabled      *bool                  `json:"enabled,omitempty"`
	MaxNodeCount *int                   `json:"maxNodeCount,omitempty"`
	MinNodeCount *int                   `json:"minNodeCount,omitempty"`
	PropertyBag  genruntime.PropertyBag `json:"$propertyBag,omitempty"`
}

// Storage version of v1api20210601.AutoScaleProperties_STATUS
// Auto-scaling properties of a Big Data pool powered by Apache Spark
type AutoScaleProperties_STATUS struct {
	Enabled      *bool                  `json:"enabled,omitempty"`
	MaxNodeCount *int                   `json:"maxNodeCount,omitempty"`
	MinNodeCount *int                   `json:"minNodeCount,omitempty"`
	PropertyBag  genruntime.PropertyBag `json:"$propertyBag,omitempty"`
}

// Storage version of v1api20210601.DynamicExecutorAllocation
// Dynamic Executor Allocation Properties
type DynamicExecutorAllocation struct {
	Enabled      *bool                  `json:"enabled,omitempty"`
	MaxExecutors *int                   `json:"maxExecutors,omitempty"`
	MinExecutors *int                   `json:"minExecutors,omitempty"`
	PropertyBag  genruntime.PropertyBag `json:"$propertyBag,omitempty"`
}

// Storage version of v1api20210601.DynamicExecutorAllocation_STATUS
// Dynamic Executor Allocation Properties
type DynamicExecutorAllocation_STATUS struct {
	Enabled      *bool                  `json:"enabled,omitempty"`
	MaxExecutors *int                   `json:"maxExecutors,omitempty"`
	MinExecutors *int                   `json:"minExecutors,omitempty"`
	PropertyBag  genruntime.PropertyBag `json:"$propertyBag,omitempty"`
}

// Storage version of v1api20210601.LibraryInfo
// Library/package information of a Big Data pool powered by Apache Spark
type LibraryInfo struct {
	ContainerName *string                `json:"containerName,omitempty"`
	Name          *string                `json:"name,omitempty"`
	Path          *string                `json:"path,omitempty"`
	PropertyBag   genruntime.PropertyBag `json:"$propertyBag,omitempty"`
	Type          *string                `json:"type,omitempty"`
}

// Storage version of v1api20210601.LibraryInfo_STATUS
// Library/package information of a Big Data pool powered by Apache Spark
type LibraryInfo_STATUS struct {
	ContainerName      *string                `json:"containerName,omitempty"`
	CreatorId          *string                `json:"creatorId,omitempty"`
	Name               *string                `json:"name,omitempty"`
	Path               *string                `json:"path,omitempty"`
	PropertyBag        genruntime.PropertyBag `json:"$propertyBag,omitempty"`
	ProvisioningStatus *string                `json:"provisioningStatus,omitempty"`
	Type               *string                `json:"type,omitempty"`
	UploadedTimestamp  *string                `json:"uploadedTimestamp,omitempty"`
}

// Storage version of v1api20210601.LibraryRequirements
// Library requirements for a Big Data pool powered by Apache Spark
type LibraryRequirements struct {
	Content     *string                `json:"content,omitempty"`
	Filename    *string                `json:"filename,omitempty"`
	PropertyBag genruntime.PropertyBag `json:"$propertyBag,omitempty"`
}

// Storage version of v1api20210601.LibraryRequirements_STATUS
// Library requirements for a Big Data pool powered by Apache Spark
type LibraryRequirements_STATUS struct {
	Content     *string                `json:"content,omitempty"`
	Filename    *string                `json:"filename,omitempty"`
	PropertyBag genruntime.PropertyBag `json:"$propertyBag,omitempty"`
	Time        *string                `json:"time,omitempty"`
}

// Storage version of v1api20210601.SparkConfigProperties
// SparkConfig Properties for a Big Data pool powered by Apache Spark
type SparkConfigProperties struct {
	ConfigurationType *string                `json:"configurationType,omitempty"`
	Content           *string                `json:"content,omitempty"`
	Filename          *string                `json:"filename,omitempty"`
	PropertyBag       genruntime.PropertyBag `json:"$propertyBag,omitempty"`
}

// Storage version of v1api20210601.SparkConfigProperties_STATUS
// SparkConfig Properties for a Big Data pool powered by Apache Spark
type SparkConfigProperties_STATUS struct {
	ConfigurationType *string                `json:"configurationType,omitempty"`
	Content           *string                `json:"content,omitempty"`
	Filename          *string                `json:"filename,omitempty"`
	PropertyBag       genruntime.PropertyBag `json:"$propertyBag,omitempty"`
	Time              *string                `json:"time,omitempty"`
}

// Storage version of v1api20210601.WorkspacesBigDataPoolOperatorSpec
// Details for configuring operator behavior. Fields in this struct are interpreted by the operator directly rather than being passed to Azure
type WorkspacesBigDataPoolOperatorSpec struct {
	ConfigMapExpressions []*core.DestinationExpression `json:"configMapExpressions,omitempty"`
	PropertyBag          genruntime.PropertyBag        `json:"$propertyBag,omitempty"`
	SecretExpressions    []*core.DestinationExpression `json:"secretExpressions,omitempty"`
}

func init() {
	SchemeBuilder.Register(&WorkspacesBigDataPool{}, &WorkspacesBigDataPoolList{})
}
