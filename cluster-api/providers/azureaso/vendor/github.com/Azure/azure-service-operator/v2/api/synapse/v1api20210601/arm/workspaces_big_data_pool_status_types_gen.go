// Code generated by azure-service-operator-codegen. DO NOT EDIT.
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
package arm

type WorkspacesBigDataPool_STATUS struct {
	// Id: Fully qualified resource ID for the resource. Ex -
	// /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/{resourceProviderNamespace}/{resourceType}/{resourceName}
	Id *string `json:"id,omitempty"`

	// Location: The geo-location where the resource lives
	Location *string `json:"location,omitempty"`

	// Name: The name of the resource
	Name *string `json:"name,omitempty"`

	// Properties: Big Data pool properties
	Properties *BigDataPoolResourceProperties_STATUS `json:"properties,omitempty"`

	// Tags: Resource tags.
	Tags map[string]string `json:"tags,omitempty"`

	// Type: The type of the resource. E.g. "Microsoft.Compute/virtualMachines" or "Microsoft.Storage/storageAccounts"
	Type *string `json:"type,omitempty"`
}

// Properties of a Big Data pool powered by Apache Spark
type BigDataPoolResourceProperties_STATUS struct {
	// AutoPause: Auto-pausing properties
	AutoPause *AutoPauseProperties_STATUS `json:"autoPause,omitempty"`

	// AutoScale: Auto-scaling properties
	AutoScale *AutoScaleProperties_STATUS `json:"autoScale,omitempty"`

	// CacheSize: The cache size
	CacheSize *int `json:"cacheSize,omitempty"`

	// CreationDate: The time when the Big Data pool was created.
	CreationDate *string `json:"creationDate,omitempty"`

	// CustomLibraries: List of custom libraries/packages associated with the spark pool.
	CustomLibraries []LibraryInfo_STATUS `json:"customLibraries,omitempty"`

	// DefaultSparkLogFolder: The default folder where Spark logs will be written.
	DefaultSparkLogFolder *string `json:"defaultSparkLogFolder,omitempty"`

	// DynamicExecutorAllocation: Dynamic Executor Allocation
	DynamicExecutorAllocation *DynamicExecutorAllocation_STATUS `json:"dynamicExecutorAllocation,omitempty"`

	// IsAutotuneEnabled: Whether autotune is required or not.
	IsAutotuneEnabled *bool `json:"isAutotuneEnabled,omitempty"`

	// IsComputeIsolationEnabled: Whether compute isolation is required or not.
	IsComputeIsolationEnabled *bool `json:"isComputeIsolationEnabled,omitempty"`

	// LastSucceededTimestamp: The time when the Big Data pool was updated successfully.
	LastSucceededTimestamp *string `json:"lastSucceededTimestamp,omitempty"`

	// LibraryRequirements: Library version requirements
	LibraryRequirements *LibraryRequirements_STATUS `json:"libraryRequirements,omitempty"`

	// NodeCount: The number of nodes in the Big Data pool.
	NodeCount *int `json:"nodeCount,omitempty"`

	// NodeSize: The level of compute power that each node in the Big Data pool has.
	NodeSize *BigDataPoolResourceProperties_NodeSize_STATUS `json:"nodeSize,omitempty"`

	// NodeSizeFamily: The kind of nodes that the Big Data pool provides.
	NodeSizeFamily *BigDataPoolResourceProperties_NodeSizeFamily_STATUS `json:"nodeSizeFamily,omitempty"`

	// ProvisioningState: The state of the Big Data pool.
	ProvisioningState *string `json:"provisioningState,omitempty"`

	// SessionLevelPackagesEnabled: Whether session level packages enabled.
	SessionLevelPackagesEnabled *bool `json:"sessionLevelPackagesEnabled,omitempty"`

	// SparkConfigProperties: Spark configuration file to specify additional properties
	SparkConfigProperties *SparkConfigProperties_STATUS `json:"sparkConfigProperties,omitempty"`

	// SparkEventsFolder: The Spark events folder
	SparkEventsFolder *string `json:"sparkEventsFolder,omitempty"`

	// SparkVersion: The Apache Spark version.
	SparkVersion *string `json:"sparkVersion,omitempty"`
}

// Auto-pausing properties of a Big Data pool powered by Apache Spark
type AutoPauseProperties_STATUS struct {
	// DelayInMinutes: Number of minutes of idle time before the Big Data pool is automatically paused.
	DelayInMinutes *int `json:"delayInMinutes,omitempty"`

	// Enabled: Whether auto-pausing is enabled for the Big Data pool.
	Enabled *bool `json:"enabled,omitempty"`
}

// Auto-scaling properties of a Big Data pool powered by Apache Spark
type AutoScaleProperties_STATUS struct {
	// Enabled: Whether automatic scaling is enabled for the Big Data pool.
	Enabled *bool `json:"enabled,omitempty"`

	// MaxNodeCount: The maximum number of nodes the Big Data pool can support.
	MaxNodeCount *int `json:"maxNodeCount,omitempty"`

	// MinNodeCount: The minimum number of nodes the Big Data pool can support.
	MinNodeCount *int `json:"minNodeCount,omitempty"`
}

type BigDataPoolResourceProperties_NodeSize_STATUS string

const (
	BigDataPoolResourceProperties_NodeSize_STATUS_Large    = BigDataPoolResourceProperties_NodeSize_STATUS("Large")
	BigDataPoolResourceProperties_NodeSize_STATUS_Medium   = BigDataPoolResourceProperties_NodeSize_STATUS("Medium")
	BigDataPoolResourceProperties_NodeSize_STATUS_None     = BigDataPoolResourceProperties_NodeSize_STATUS("None")
	BigDataPoolResourceProperties_NodeSize_STATUS_Small    = BigDataPoolResourceProperties_NodeSize_STATUS("Small")
	BigDataPoolResourceProperties_NodeSize_STATUS_XLarge   = BigDataPoolResourceProperties_NodeSize_STATUS("XLarge")
	BigDataPoolResourceProperties_NodeSize_STATUS_XXLarge  = BigDataPoolResourceProperties_NodeSize_STATUS("XXLarge")
	BigDataPoolResourceProperties_NodeSize_STATUS_XXXLarge = BigDataPoolResourceProperties_NodeSize_STATUS("XXXLarge")
)

// Mapping from string to BigDataPoolResourceProperties_NodeSize_STATUS
var bigDataPoolResourceProperties_NodeSize_STATUS_Values = map[string]BigDataPoolResourceProperties_NodeSize_STATUS{
	"large":    BigDataPoolResourceProperties_NodeSize_STATUS_Large,
	"medium":   BigDataPoolResourceProperties_NodeSize_STATUS_Medium,
	"none":     BigDataPoolResourceProperties_NodeSize_STATUS_None,
	"small":    BigDataPoolResourceProperties_NodeSize_STATUS_Small,
	"xlarge":   BigDataPoolResourceProperties_NodeSize_STATUS_XLarge,
	"xxlarge":  BigDataPoolResourceProperties_NodeSize_STATUS_XXLarge,
	"xxxlarge": BigDataPoolResourceProperties_NodeSize_STATUS_XXXLarge,
}

type BigDataPoolResourceProperties_NodeSizeFamily_STATUS string

const (
	BigDataPoolResourceProperties_NodeSizeFamily_STATUS_HardwareAcceleratedFPGA = BigDataPoolResourceProperties_NodeSizeFamily_STATUS("HardwareAcceleratedFPGA")
	BigDataPoolResourceProperties_NodeSizeFamily_STATUS_HardwareAcceleratedGPU  = BigDataPoolResourceProperties_NodeSizeFamily_STATUS("HardwareAcceleratedGPU")
	BigDataPoolResourceProperties_NodeSizeFamily_STATUS_MemoryOptimized         = BigDataPoolResourceProperties_NodeSizeFamily_STATUS("MemoryOptimized")
	BigDataPoolResourceProperties_NodeSizeFamily_STATUS_None                    = BigDataPoolResourceProperties_NodeSizeFamily_STATUS("None")
)

// Mapping from string to BigDataPoolResourceProperties_NodeSizeFamily_STATUS
var bigDataPoolResourceProperties_NodeSizeFamily_STATUS_Values = map[string]BigDataPoolResourceProperties_NodeSizeFamily_STATUS{
	"hardwareacceleratedfpga": BigDataPoolResourceProperties_NodeSizeFamily_STATUS_HardwareAcceleratedFPGA,
	"hardwareacceleratedgpu":  BigDataPoolResourceProperties_NodeSizeFamily_STATUS_HardwareAcceleratedGPU,
	"memoryoptimized":         BigDataPoolResourceProperties_NodeSizeFamily_STATUS_MemoryOptimized,
	"none":                    BigDataPoolResourceProperties_NodeSizeFamily_STATUS_None,
}

// Dynamic Executor Allocation Properties
type DynamicExecutorAllocation_STATUS struct {
	// Enabled: Indicates whether Dynamic Executor Allocation is enabled or not.
	Enabled *bool `json:"enabled,omitempty"`

	// MaxExecutors: The maximum number of executors alloted
	MaxExecutors *int `json:"maxExecutors,omitempty"`

	// MinExecutors: The minimum number of executors alloted
	MinExecutors *int `json:"minExecutors,omitempty"`
}

// Library/package information of a Big Data pool powered by Apache Spark
type LibraryInfo_STATUS struct {
	// ContainerName: Storage blob container name.
	ContainerName *string `json:"containerName,omitempty"`

	// CreatorId: Creator Id of the library/package.
	CreatorId *string `json:"creatorId,omitempty"`

	// Name: Name of the library.
	Name *string `json:"name,omitempty"`

	// Path: Storage blob path of library.
	Path *string `json:"path,omitempty"`

	// ProvisioningStatus: Provisioning status of the library/package.
	ProvisioningStatus *string `json:"provisioningStatus,omitempty"`

	// Type: Type of the library.
	Type *string `json:"type,omitempty"`

	// UploadedTimestamp: The last update time of the library.
	UploadedTimestamp *string `json:"uploadedTimestamp,omitempty"`
}

// Library requirements for a Big Data pool powered by Apache Spark
type LibraryRequirements_STATUS struct {
	// Content: The library requirements.
	Content *string `json:"content,omitempty"`

	// Filename: The filename of the library requirements file.
	Filename *string `json:"filename,omitempty"`

	// Time: The last update time of the library requirements file.
	Time *string `json:"time,omitempty"`
}

// SparkConfig Properties for a Big Data pool powered by Apache Spark
type SparkConfigProperties_STATUS struct {
	// ConfigurationType: The type of the spark config properties file.
	ConfigurationType *SparkConfigProperties_ConfigurationType_STATUS `json:"configurationType,omitempty"`

	// Content: The spark config properties.
	Content *string `json:"content,omitempty"`

	// Filename: The filename of the spark config properties file.
	Filename *string `json:"filename,omitempty"`

	// Time: The last update time of the spark config properties file.
	Time *string `json:"time,omitempty"`
}

type SparkConfigProperties_ConfigurationType_STATUS string

const (
	SparkConfigProperties_ConfigurationType_STATUS_Artifact = SparkConfigProperties_ConfigurationType_STATUS("Artifact")
	SparkConfigProperties_ConfigurationType_STATUS_File     = SparkConfigProperties_ConfigurationType_STATUS("File")
)

// Mapping from string to SparkConfigProperties_ConfigurationType_STATUS
var sparkConfigProperties_ConfigurationType_STATUS_Values = map[string]SparkConfigProperties_ConfigurationType_STATUS{
	"artifact": SparkConfigProperties_ConfigurationType_STATUS_Artifact,
	"file":     SparkConfigProperties_ConfigurationType_STATUS_File,
}
